---
title: Registrazioni di sessione di Mixed Reality Dev Days
description: Pagina della sessione con collegamenti video per MR Dev Days
author: jessemcculloch
ms.author: jemccull
ms.date: 02/21/2020
ms.topic: article
keywords: Realtà mista, conferenza, vertice, sviluppatore, HoloLens, HoloLens 2, Kinect
ms.openlocfilehash: b0fbb0d587470d72c436981443c80299a62b2645b9b860b3abe0b05726930871
ms.sourcegitcommit: a1c086aa83d381129e62f9d8942f0fc889ffcab0
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 08/05/2021
ms.locfileid: "115209781"
---
# <a name="session-details-and-recordings"></a>Registrazioni e dettagli della sessione

![Mixed Reality Dev Days](images/MRDD/MRDevDaysBanner.png)

|**Titolo della sessione**|**Relatore**|**Descrizione**|
|---------|---------|---------|
|[Apertura di keynote](https://aka.ms/MRDDKeynote)|Alex Kipman|Alex Kipman inizia il primo evento virtual mixed reality Dev Days.|
|[Introduzione ai Realtà mista di Azure seguenti: Rendering remoto di Azure](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Intro-to-Azure-Mixed-Reality-Services-Azure-Remote-Rendering)|Antonio Lyons, Christopher Manthei e Appelsmeier|Rendering remoto di Azure anteprima pubblica.  Informazioni sul rendering e lo streaming di modelli 3D interattivi con centinaia di milioni di poligoni in dispositivi come HoloLens 2 in tempo reale.|
|[Introduzione a Unreal + MRTK per HoloLens 2](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Intro-to-Unreal--MRTK-for-HoloLens-2)|Estate Wu & Luis Valverde|Il supporto di Unreal Engine HoloLens 2 stato pronto per la produzione con il rilascio di UE 4.25 a maggio. Insieme a UE 4.25, in risposta alle principali domande degli sviluppatori dal momento in cui il supporto HoloLens di Unreal è stato fornito in anteprima, il team ha rilasciato il primo componente di Mixed Reality Toolkit for Unreal: UX Tools 0.8. In questo discorso verrà fornita una panoramica delle funzionalità fornite in Unreal Engine 4 e MRTK per Unreal e verrà illustrato come usarle per creare esperienze epiche per HoloLens 2.|
|[Introduzione a HoloLens 2 e Unity](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Getting-started-with-the-HoloLens-2-and-Unity)|Dan Miller - Unity|Informazioni di base sulla configurazione di Unity e sulla compilazione per HoloLens 2. Questa presentazione illustra le procedure consigliate, le funzionalità di base del HoloLens 2 e come aggiungere rapidamente il supporto del tracciamento delle mani e l'interattività con le API unity native|
|[Introduzione ai servizi Realtà mista di Azure: Ancoraggi nello stato di Azure](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Intro-to-Azure-Mixed-Reality-Services-Azure-Spatial-Anchors)|Archana Iyer & Vicente Rivera|Panoramica di Ancoraggi nello stato di Azure e degli scenari pertinenti. Questo discorso illustra le nuove funzionalità sviluppate nell'anno precedente, con esempi di codice su come usarle. Verranno trattate le procedure consigliate durante la compilazione con ASA e verrà illustrato come iniziare a integrarlo nei prodotti.|
|[Introduzione a MRTK-Unity](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Intro-to-MRTK-Unity)|Catherine Diaz|La sessione Introduction to MRTK (Introduzione a MRTK) sarà un'esercitazione su come creare un'app MRTK dall'inizio alla fine.  Questo discorso illustra i concetti di interazione e mostra le funzionalità multipiattaforma di MRTK.|
|[Apprendimento dall'app Mr Surfaces](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Learnings-from-the-MR-Surfaces-App)|Lars Simkins|Unirsi ai tecnici alla base dell'app MRDL Surfaces per HoloLens 2 quando si parla della storia di progettazione dell'app e dei punti di rilievo tecnici.|
|[Integrazione di Unity Kinect body tracking di Azure](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Azure-Kinect-Body-Tracking-Unity-Integration)|Aley Antley| Informazioni su come usare i caratteri in Unity con Azure Kinect Body Tracking SDK.|
|[Blocchi predefiniti per l'esperienza utente di MRTK](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/MRTKs-UX-Building-Blocks)|Yoon Park|Approfondimenti sui componenti dell'esperienza utente di MRTK che consentono di creare esperienze di realtà mista eccezionali.|
|[Strumenti per le prestazioni di MRTK](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/MRTK-Performance-and-Shaders)|Kurtis Eveleigh & David Kline|Introduzione agli strumenti per le prestazioni, sia in MRTK che esterni, e una panoramica dello shader MRTK Standard.|
|[Stato della realtà mista: dove le aziende trovano il successo](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/The-State-of-Mixed-Reality-Where-Companies-are-finding-Success)|Ori Amiga & Matt Fleck kpi|La latenza estremamente bassa edge computing, abbinata all'intelligenza artificiale e alla realtà mista, è la base per la prossima generazione di esperienze. Combinando il mondo digitale e il mondo fisico in esperienze di elaborazione onnipresenti, la realtà mista consente di realizzare possibilità che in precedenza si potevano solo realizzare. In questa sessione Ori e Matt forniranno informazioni dettagliate uniche sull'opportunità di mercato della realtà mista oggi e in futuro. Verrà illustrato in che modo Microsoft aiuta le aziende leader nel settore della produzione, dell'assistenza sanitaria e della vendita al dettaglio a sfruttare la potenza della realtà mista per migliorare l'efficienza aziendale e trasformare le esperienze di clienti e dipendenti.|
|[Fireside Chat](https://aka.ms/MRDDFireside)|Alex Kipman & Retr Schulte|Aprendo il giorno due, abbiamo invitato Microsoft MVP, Regional Director e il membro della community, re renzitano Schulte, a partecipare a un incendio e a parlare degli argomenti a cui la community è interessata. Renato raccoglie domande dalla community da circa una settimana e si prevede che si tratta di una conversazione interessante.|
|[Progettazione di esperienze AR/VR con Microsoft Maquette](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Designing-ARVR-experiences-using-Microsoft-Maquette)|Ricardo Acosta|La progettazione di un'app per telefoni o di un sito Web ha un flusso di lavoro ben definito. Sfortunatamente, a causa della sua novità, la progettazione di esperienze di realtà spaziale può essere difficile se si usa lo stesso flusso di lavoro o set di strumenti 2D. Fortunatamente, la nuova app Microsoft Maquette è incentrata sull'aiutare i progettisti di esperienza utente a progettare.|
|[MrTK Unity v2 non &: in che modo il feedback della community ha contribuito a migliorare MRTK](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/MRTK-Unity-v2-and-beyond-How-community-feedback-helped-us-improve-MRTK)|Adette Thalhammer|Si è parlato di come è stata migliorata l'esperienza degli sviluppatori nell'ultimo anno, grazie all'ascolto dei commenti e suggerimenti della community e al modo in cui gli sviluppatori possono sfruttare questi miglioramenti. Verranno esaminati la documentazione e gli unit test, il nuovo componente manipolatore di oggetti, usando la finestra di migrazione e verranno esaminati alcuni frammenti di codice relativi alle domande più frequenti della community di sviluppatori.|
|[Plug-in Unreal Engine di Dark Slope per Azure Kinect DK](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Dark-Slopes-Unreal-Engine-plugin-for-the-Azure-Kinect-DK)|Ben Unsworth - Dark Slope|Informazioni su come Dark Slope usa Azure Kinect DK e i relativi SDK per creare engagement interattivi in tempo reale in Unreal Engine.|
|[Introduzione a StereoKit - MR Made Easy!](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Introducing-StereoKit-MR-Made-Easy)|Nick Klingensmith|StereoKit è una libreria di realtà mista open source facile da usare per la creazione di applicazioni HoloLens e VR con C# e OpenXR. StereoKit dà priorità allo sviluppo di applicazioni di realtà mista, consentendo funzionalità come un sistema di input di realtà mista di prima classe, prestazioni veloci per impostazione predefinita anche nei dispositivi mobili, tempi di iterazione rapida su dispositivo e una pipeline di asset di runtime che consente a utenti e sviluppatori di caricare asset reali dal file system. Tutto questo e altro ancora sono disponibili in un'API ben documentata, facile da imparare e facile da scrivere.|
|[Creazione di esperienze immersive di mr con Babylon.js e WebXR](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Building-Immersive-MR-Experiences-with-Babylonjs-and-WebXR)|Jason Carter & Raanan Weber|Scoprire quanto può essere semplice e potente sviluppare esperienze di mr direttamente sul Web. Babylon.js si impegna a essere una delle piattaforme di rendering Web più potenti, efficaci, semplici e aperte al mondo, semplificando lo sblocco delle funzionalità mr complete su piattaforme, dispositivi ed ecosistemi. Scopri gli ultimi sviluppi di Babylon.js e il supporto di WebXR.|
|[Uso Project Acustica con HoloLens 2](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Using-Project-Acoustics-with-HoloLens-2)|Mike Chemistruck|Scopri come Project Acoustics, in precedenza disponibile solo per i titoli vr e console, può essere applicato alla realtà mista. Informazioni su come il sistema ricrea gli effetti reali, ad esempio l'occlusione e il reindirizzamento dei suoni intorno a porte e angoli fisici e il riverbero in geometrie complesse con più spazi connessi, il tutto entro il budget di calcolo di un HoloLens 2.|
|[Holographic Remoting : iterazione rapida & grafica con sovraccarico HoloLens](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Holographic-Remoting-Rapid-iteration-and-superharged-graphics-on-HoloLens)|Brent Jackson|HoloLens offre come nessun'altra piattaforma di mobile computing, ma è limitata alla potenza di elaborazione di un dispositivo mobile. Holographic Remoting porta la potenza non elaborata di un computer con funzionalità di realtà virtuale HoloLens e con la comunicazione remota nell'editor di Unity non è più necessario compilare e distribuire le app per testarle in un dispositivo. Informazioni su come holographic remoting può migliorare le prestazioni delle applicazioni e degli sviluppatori.|
|[OpenXR in HoloLens 2: Realtà mista nativa multipiattaforma](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/OpenXR-on-HoloLens-2-Cross-platform-native-mixed-reality)|Alex Turner|OpenXR 1.0 è disponibile qui. Si sta creando il supporto di realtà mista nel proprio motore o in un'app nativa da zero? In questo caso, è possibile ottenere informazioni sui dettagli principali della superficie dell'API nativa OpenXR, sulle estensioni che attivano l'intero set di funzionalità di HoloLens 2 e sui partner da Firefox Reality a StereoKit che già spedirà app e framework compilati su OpenXR. Con OpenXR è possibile creare motori di realtà mista tra fornitori e app native che si estendono su un'ampiezza di dispositivi nel settore.|
|[Suggerimenti da un anno di sviluppo HoloLens 2](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Tips-from-a-Year-of-HoloLens-2-Development)|Peter Vale|Il team HoloLens commercializzazione condividerà i suggerimenti e le lezioni apprese dall'anno precedente collaborando con i partner.  Ottenere informazioni dettagliate sui problemi più comuni insieme alle procedure consigliate e alle tecniche che è possibile usare per ottenere l'applicazione HoloLens 2 pronta per la condivisione con i clienti.|
|||||

--- 
