---
title: Visione artificiale applicazioni per il laboratorio di auricolari con realtà mista a CVPR 2019
description: Panoramica e pianificazione del workshop sulle applicazioni Visione artificiale per gli auricolari a realtà mista, da consegnare alla conferenza CVPR il 2019 giugno.
author: fbogo
ms.author: febogo
ms.date: 1/9/2019
ms.topic: article
keywords: evento, modalità di ricerca, cvpr, visione artificiale, ricerca, HoloLens
ms.openlocfilehash: 55fbeea1f1293c7df5eae489b6504851bf6bca7f
ms.sourcegitcommit: 09599b4034be825e4536eeb9566968afd021d5f3
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 10/03/2020
ms.locfileid: "91687109"
---
# <a name="computer-vision-applications-for-mixed-reality-headsets"></a>Visione artificiale applicazioni per cuffie con realtà mista

Organizzata insieme a [CVPR 2019](https://cvpr2019.thecvf.com/)

Long Beach (CA)

17 giugno 2019 (pomeriggio)-Hyatt Regency F


## <a name="organizers"></a>Librerie
* Marc Pollefeys
* Federica Bogo
* Di Johannes Schönberger
* Osman Ulusoy

## <a name="overview"></a>Panoramica

![Immagine del teaser](images/cvpr2019_teaser2.jpg)

Gli auricolari per la realtà mista, ad esempio Microsoft HoloLens, diventano piattaforme potenti per sviluppare applicazioni di visione artificiale. La modalità di ricerca di HoloLens consente la ricerca di visione artificiale sul dispositivo fornendo l'accesso a tutti i flussi dei sensori di immagini RAW, inclusi Depth e IR. Poiché la modalità di ricerca è ora disponibile a partire dal 2018 maggio, verranno visualizzate diverse demo e applicazioni interessanti sviluppate per HoloLens. 

L'obiettivo di questo workshop è riunire gli studenti e i ricercatori interessati alla visione artificiale per le applicazioni di realtà mista. Il workshop fornirà una sede per condividere demo e applicazioni e imparare tra loro per creare o trasferire applicazioni in realtà mista. 

Invitiamo gli invii per gli argomenti relativi al riconoscimento degli oggetti (incentrato sugli ego), al rilevamento di utenti e utenti, al riconoscimento delle attività, allo SLAM, alla ricostruzione 3D, alla comprensione della scena, alla localizzazione basata su sensori, alla navigazione e molto altro.

## <a name="paper-submission"></a>Invio di carta
* Scadenza di invio del documento: 17 maggio
* Notifica agli autori: 24 maggio

Gli invii cartacei devono usare il modello CVPR e sono limitati a 4 pagine oltre ai riferimenti. Inoltre, invitiamo gli autori a inviare un video che mostra la propria applicazione.
Si noti che sono consentiti invii di lavoro pubblicati in precedenza (incluso il lavoro accettato alla conferenza principale CVPR 2019). 

Gli invii possono essere caricati in CMT: https://cmt3.research.microsoft.com/CVFORMR2019

Un subset di documenti verrà selezionato per la presentazione orale nel workshop. Tuttavia, si consiglia vivamente a tutti gli autori di presentare il proprio lavoro durante la sessione dimostrativa.


## <a name="schedule"></a>Pianifica
* 13:30-13:45: Note introduttive e apertura.
* 13:45-14:15: **discussione introduttiva** : Prof. Marc POLLEFEYS, ETH Zurigo/Microsoft. Titolo: egocentrico Visione artificiale in HoloLens.
* 14:15-14:45: **discussione introduttiva** : Prof. Kris Kitani, Carnegie Mellon University. Titolo: attività egocentrico e previsione della posizione.
* 14:45-15:15: **discussione introduttiva** : Dr. Yang Liu, California Institute of Technology. Titolo: il potenziamento di un assistente cognitivo per la cecità con realtà aumentata.
* 15:15-16:15: coffee break e demo.
* 16:15-16:45: **discussione introduttiva** : Prof. Kristen Graun, University of Texas at Austin/Facebook ai Research. Title: interazione Human-Object nel video della prima persona.
* 16:45-17:15: presentazioni orali:
    * La registrazione è stata semplificata per la navigazione ortopedica autonoma con HoloLens. F. Liebmann, S. Roner, M. von Atzigen, F. Wanivenhaus, C. Neuhaus, J. Spirig, D. Scaramuzza, R. Sutter, J. Snedeker, M. figo, P. Furnstahl.
    * Imparare a usare lo stereo con una HoloLens. H. Zhan, Y. Pekelny, O. Ulusoy.
* 17:15-17:30: osservazioni finali.
